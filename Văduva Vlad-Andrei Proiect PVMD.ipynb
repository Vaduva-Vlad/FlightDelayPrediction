{"cells": [{"cell_type": "code", "execution_count": 2, "id": "f5220b88-ef96-4089-95b2-bab95fbd08ea", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/06/22 16:21:32 INFO SparkEnv: Registering MapOutputTracker\n24/06/22 16:21:32 INFO SparkEnv: Registering BlockManagerMaster\n24/06/22 16:21:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/06/22 16:21:33 INFO SparkEnv: Registering OutputCommitCoordinator\n"}, {"name": "stdout", "output_type": "stream", "text": "<pyspark.sql.session.SparkSession object at 0x7fc4d71c34d0>\n"}], "source": "from pyspark.sql import SparkSession\n#spark =  SparkSession.builder.appName('Processing').getOrCreate()\nspark =  SparkSession.builder.appName('Processing')\\\n.master(\"yarn\")\\\n.config(\"spark.executor.memory\",\"12g\")\\\n.config(\"spark.executor.cores\",\"2\")\\\n.config(\"spark.executor.instances\",\"3\")\\\n.getOrCreate()\nprint(spark)\n"}, {"cell_type": "code", "execution_count": 3, "id": "81f34ae4-aa46-4bb9-820a-29fda78cd385", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, TimestampType\nfrom pyspark.sql.functions import isnull, when, count, col, desc"}, {"cell_type": "code", "execution_count": 4, "id": "9cf4f296-4d39-4f4d-bb21-109a03e0ef9d", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "6311871"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "df = spark.read.csv(\"hdfs:///user/data/pvmdstorage/Flights_2021_1.csv\",header=True)\nfor i in range(2,13):\n    df=df.union(spark.read.csv(f\"hdfs:///user/data/pvmdstorage/Flights_2021_{i}.csv\",header=True))\ndf.count()"}, {"cell_type": "code", "execution_count": 4, "id": "1c858b9e-a31f-4bb2-9947-b28049a9694c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------------------------------------------------------+\n|count(CASE WHEN (DepDelayMinutes IS NULL) THEN DepDelayMinutes END)|\n+-------------------------------------------------------------------+\n|                                                             108413|\n+-------------------------------------------------------------------+\n\n+-------------------------------------------------------------------+\n|count(CASE WHEN (ArrDelayMinutes IS NULL) THEN ArrDelayMinutes END)|\n+-------------------------------------------------------------------+\n|                                                             126001|\n+-------------------------------------------------------------------+\n\n"}], "source": "#numaram valorile nule din DepDelayMinutes\ndf.select(count(when(isnull(\"DepDelayMinutes\"),\"DepDelayMinutes\"))).show()\ndf.select(count(when(isnull(\"ArrDelayMinutes\"),\"ArrDelayMinutes\"))).show()"}, {"cell_type": "code", "execution_count": 5, "id": "861c18af-28db-4e70-a6ca-de0b7786b86e", "metadata": {"tags": []}, "outputs": [], "source": "df=df.select(*(col(c).cast(\"float\").alias(c) for c in df.columns))"}, {"cell_type": "code", "execution_count": 32, "id": "6b7e75fd-085c-4bb2-9427-7f126722d283", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Year: nan\nQuarter: 0.023337430831709513\nMonth: 0.024645759396537747\nDayofMonth: 0.0047066972077218\nDayOfWeek: 0.00023115613608019217\nFlightDate: nan\nMarketing_Airline_Network: nan\nOperated_or_Branded_Code_Share_Partners: nan\nDOT_ID_Marketing_Airline: -0.02481471185520768\nIATA_Code_Marketing_Airline: nan\nFlight_Number_Marketing_Airline: 0.01670329707122373\nOriginally_Scheduled_Code_Share_Airline: nan\nDOT_ID_Originally_Scheduled_Code_Share_Airline: 0.023565365250150596\nIATA_Code_Originally_Scheduled_Code_Share_Airline: nan\nFlight_Num_Originally_Scheduled_Code_Share_Airline: 0.02408811176475596\nOperating_Airline : nan\nDOT_ID_Operating_Airline: -0.01806040149379832\nIATA_Code_Operating_Airline: nan\nTail_Number: nan\nFlight_Number_Operating_Airline: 0.01669536140763225\nOriginAirportID: -0.0022179493696779717\nOriginAirportSeqID: -0.0022180443811063984\nOriginCityMarketID: -0.009431711240518182\nOrigin: nan\nOriginCityName: nan\nOriginState: nan\nOriginStateFips: 0.0008312922101911207\nOriginStateName: nan\nOriginWac: 0.01607967876210794\nDestAirportID: 0.0009608783565470528\nDestAirportSeqID: 0.0009608494539948153\nDestCityMarketID: -0.004803783832090724\nDest: nan\nDestCityName: nan\nDestState: nan\nDestStateFips: 0.005800215542164715\nDestStateName: nan\nDestWac: 0.012133035508829507\nCRSDepTime: 0.08190024054351384\nDepTime: 0.1164547025790649\nDepDelay: 0.9707182868414671\nDepDelayMinutes: 0.9751625430251804\nDepDel15: 0.49457878756823936\nDepartureDelayGroups: 0.7819673508885441\nDepTimeBlk: nan\nTaxiOut: 0.11999089016213436\nWheelsOff: 0.11220352376070257\nWheelsOn: 0.035222867417850974\nTaxiIn: 0.07788001470064598\nCRSArrTime: 0.06786864605817207\nArrTime: 0.029558530902796996\nArrDelay: 0.9801752737197071\nArrDelayMinutes: 1.0\nArrDel15: 0.5423150700728632\nArrivalDelayGroups: 0.7954757858123017\nArrTimeBlk: nan\nCancelled: -0.03768838070466904\nCancellationCode: nan\nDiverted: -0.012807269604950641\nCRSElapsedTime: -0.0015801990662197018\nActualElapsedTime: 0.03804148007459669\nAirTime: 0.01718929385470024\nFlights: nan\nDistance: 0.0016333869133339824\nDistanceGroup: 0.0011894147922909173\nCarrierDelay: 0.7086173991000332\nWeatherDelay: 0.3585812265197486\nNASDelay: 0.3208392281068253\nSecurityDelay: 0.04961363892030656\nLateAircraftDelay: 0.5787983526714061\nFirstDepTime: 0.1816251609780576\nTotalAddGTime: 0.19898156142852957\nLongestAddGTime: 0.1979982231499024\nDivAirportLandings: -0.008511920067353749\nDivReachedDest: -0.012199678675832477\nDivActualElapsedTime: -0.010563837505300936\nDivArrDelay: -0.009147793149399279\nDivDistance: -0.002654690540962117\nDiv1Airport: nan\nDiv1AirportID: -0.012952479957736249\nDiv1AirportSeqID: -0.012952480800898475\nDiv1WheelsOn: -0.012436564072713215\nDiv1TotalGTime: -0.009590671265779229\nDiv1LongestGTime: -0.00908177404541607\nDiv1WheelsOff: -0.011509677103288986\nDiv1TailNum: nan\nDiv2Airport: nan\nDiv2AirportID: -0.0012233533728722183\nDiv2AirportSeqID: -0.0012233534427982518\nDiv2WheelsOn: -0.0010470910000603775\nDiv2TotalGTime: -0.0008380805908410062\nDiv2LongestGTime: -0.000807026786667914\nDiv2WheelsOff: -0.0007214970242813458\nDiv2TailNum: nan\nDiv3Airport: nan\nDiv3AirportID: nan\nDiv3AirportSeqID: nan\nDiv3WheelsOn: nan\nDiv3TotalGTime: nan\nDiv3LongestGTime: nan\nDiv3WheelsOff: nan\nDiv3TailNum: nan\nDiv4Airport: nan\nDiv4AirportID: nan\nDiv4AirportSeqID: nan\nDiv4WheelsOn: nan\nDiv4TotalGTime: nan\nDiv4LongestGTime: nan\nDiv4WheelsOff: nan\nDiv4TailNum: nan\nDiv5Airport: nan\nDiv5AirportID: nan\nDiv5AirportSeqID: nan\nDiv5WheelsOn: nan\nDiv5TotalGTime: nan\nDiv5LongestGTime: nan\nDiv5WheelsOff: nan\nDiv5TailNum: nan\nDuplicate: nan\n_c119: nan\n"}], "source": "#Determinam coloanele care au cele mai mari corelatii cu coloana ArrDelay\nfor column in df.columns:\n    correlation=df.stat.corr(column,\"ArrDelayMinutes\")\n    print(f\"{column}: {correlation}\")"}, {"cell_type": "code", "execution_count": 6, "id": "d1f4cac2-c3b7-4f8e-9061-5b2e7b75be1d", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Vom utiliza coloanele DepDelayMinutes,CarrierDelay,WeatherDelay,NASDelay,LateAircraftDelay\n\nfrom pyspark.ml.feature import Imputer\nimputer = Imputer()\nimputer.setInputCols([\"DepDelayMinutes\",\"CarrierDelay\",\"WeatherDelay\",\"NASDelay\",\"LateAircraftDelay\",\"ArrDelayMinutes\"])\nimputer.setOutputCols([\"out_DepDelayMinutes\",\"out_CarrierDelay\",\"out_WeatherDelay\",\"out_NASDelay\",\"out_LateAircraftDelay\",\"out_ArrDelayMinutes\"])\nmodel=imputer.fit(df)\nimputed_df=model.transform(df)"}, {"cell_type": "code", "execution_count": 7, "id": "c494c6c5-44c2-4437-b6a6-40fc53f7e7df", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------------------------------------------------------------------+\n|count(CASE WHEN (out_DepDelayMinutes IS NULL) THEN out_DepDelayMinutes END)|\n+---------------------------------------------------------------------------+\n|                                                                          0|\n+---------------------------------------------------------------------------+\n\n+---------------------------------------------------------------------+\n|count(CASE WHEN (out_CarrierDelay IS NULL) THEN out_CarrierDelay END)|\n+---------------------------------------------------------------------+\n|                                                                    0|\n+---------------------------------------------------------------------+\n\n+---------------------------------------------------------------------+\n|count(CASE WHEN (out_WeatherDelay IS NULL) THEN out_WeatherDelay END)|\n+---------------------------------------------------------------------+\n|                                                                    0|\n+---------------------------------------------------------------------+\n\n+-------------------------------------------------------------+\n|count(CASE WHEN (out_NASDelay IS NULL) THEN out_NASDelay END)|\n+-------------------------------------------------------------+\n|                                                            0|\n+-------------------------------------------------------------+\n\n+-------------------------------------------------------------------------------+\n|count(CASE WHEN (out_LateAircraftDelay IS NULL) THEN out_LateAircraftDelay END)|\n+-------------------------------------------------------------------------------+\n|                                                                              0|\n+-------------------------------------------------------------------------------+\n\n+---------------------------------------------------------------------------+\n|count(CASE WHEN (out_ArrDelayMinutes IS NULL) THEN out_ArrDelayMinutes END)|\n+---------------------------------------------------------------------------+\n|                                                                          0|\n+---------------------------------------------------------------------------+\n\n"}], "source": "imputed_df.select(count(when(isnull(\"out_DepDelayMinutes\"),\"out_DepDelayMinutes\"))).show()\nimputed_df.select(count(when(isnull(\"out_CarrierDelay\"),\"out_CarrierDelay\"))).show()\nimputed_df.select(count(when(isnull(\"out_WeatherDelay\"),\"out_WeatherDelay\"))).show()\nimputed_df.select(count(when(isnull(\"out_NASDelay\"),\"out_NASDelay\"))).show()\nimputed_df.select(count(when(isnull(\"out_LateAircraftDelay\"),\"out_LateAircraftDelay\"))).show()\nimputed_df.select(count(when(isnull(\"out_ArrDelayMinutes\"),\"out_ArrDelayMinutes\"))).show()"}, {"cell_type": "code", "execution_count": 7, "id": "154c9da2-187a-4bbb-a0a2-01330d107f62", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 21:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+\n|            features|out_ArrDelayMinutes|\n+--------------------+-------------------+\n|[3.0,26.829744338...|                0.0|\n|[0.0,26.829744338...|                0.0|\n|[7.0,26.829744338...|                0.0|\n|[0.0,26.829744338...|                0.0|\n|[0.0,26.829744338...|               14.0|\n+--------------------+-------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=[\"out_DepDelayMinutes\",\"out_CarrierDelay\",\"out_WeatherDelay\",\"out_NASDelay\",\"out_LateAircraftDelay\"], outputCol='features')\noutput = assembler.transform(imputed_df)\nfinal_df=output.select('features','out_ArrDelayMinutes')\nfinal_df.show(5)\ntrain_data, test_data = final_df.randomSplit([0.7, 0.3])"}, {"cell_type": "code", "execution_count": 8, "id": "7bf321d9-f791-427f-892a-095c73b50a8a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/06/22 16:24:40 WARN Instrumentation: [466ca35d] regParam is zero, which might cause numerical instability and overfitting.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Training time (s):  45.54967260360718\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 28:======================================================> (70 + 2) / 72]\r"}, {"name": "stdout", "output_type": "stream", "text": "+------------------+\n|         residuals|\n+------------------+\n| 330.7836148668674|\n|282.07723972209305|\n|178.12983128999366|\n|174.01464807541248|\n| 170.4872306925384|\n|169.01463292992858|\n| 163.0887492886651|\n| 161.5984026040411|\n|161.25809391460615|\n| 157.6226663808742|\n|157.44870403903928|\n|157.43515345741912|\n|155.80056229324487|\n|148.29178648091846|\n|147.02332290557024|\n|144.83371587784765|\n|140.06954313852984|\n|139.41942746288746|\n|136.16884908467554|\n|135.83577867253445|\n+------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.regression import LinearRegression\nfrom pyspark.sql import functions as F\nimport time\nlr = LinearRegression(labelCol='out_ArrDelayMinutes')\n\nstart=time.time()\nlr_model = lr.fit(train_data)\nend=time.time()\nduration=end-start\nprint(\"Training time (s): \", duration)\ntest_results = lr_model.evaluate(test_data)\ntest_results.residuals.orderBy(F.col('residuals').desc()).show()"}, {"cell_type": "code", "execution_count": 9, "id": "964f3ae5-db8c-4160-ba68-efff108fcc81", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "9.323882152315441"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "test_results.rootMeanSquaredError"}, {"cell_type": "code", "execution_count": 10, "id": "137ea116-8e6e-4861-b184-4bf42eee84ef", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "0.9592851628385844"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "test_results.r2"}, {"cell_type": "code", "execution_count": 11, "id": "3afc3076-1586-4ea2-8615-4ea76306bfc7", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Mean Absolute Percentage Error (MAPE): 78.27%\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 32:======================================================> (70 + 2) / 72]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+------------------+-------------------------+\n|            features|out_ArrDelayMinutes|        prediction|absolute_percentage_error|\n+--------------------+-------------------+------------------+-------------------------+\n|[2554.0,2554.0,0....|             2565.0|2502.0631840931887|      0.02453677033403948|\n|[2369.0,2365.0,0....|             2371.0| 2317.387545193687|       0.0226117481258174|\n|[2112.0,2112.0,0....|             2135.0|2072.7400471673764|      0.02916157041340686|\n|[1961.0,1877.0,0....|             1934.0|1913.4864113917768|     0.010606819342411191|\n|[1915.0,20.0,0.0,...|             1890.0|1834.4033436840577|      0.02941622027298532|\n|[1773.0,1773.0,0....|             1782.0| 1735.344216740992|       0.0261816965538766|\n|[1757.0,22.0,1740...|             1762.0|1760.4661367088597|     8.705240017822238E-4|\n|[1710.0,1710.0,0....|             1722.0|1674.6023082309414|      0.02752479196809443|\n|[1707.0,224.0,0.0...|             1682.0|1638.1458443611073|     0.026072625231208523|\n|[1676.0,1676.0,0....|             1678.0|1637.7556381552033|     0.023983529108937238|\n|[1670.0,1670.0,0....|             1747.0|1658.1120518645841|      0.05088033665450249|\n|[1646.0,1646.0,0....|             1671.0| 1616.378424528227|      0.03268795659591441|\n|[1634.0,1634.0,0....|             1646.0|1600.0601070766972|      0.02791002000200653|\n|[1605.0,1605.0,0....|             1639.0|1579.3138275616034|     0.036416212592066274|\n|[1559.0,0.0,0.0,1...|             1560.0|1493.3137965190247|      0.04274756633395855|\n|[1557.0,1557.0,0....|             1597.0|1534.3338485682266|      0.03923991949390947|\n|[1552.0,1552.0,0....|             1557.0|1517.1838050345095|     0.025572379553943782|\n|[1551.0,1464.0,0....|             1559.0|1515.6155328210916|     0.027828394598401782|\n|[1519.0,0.0,0.0,3...|             1522.0|1455.5335204768737|      0.04367048588904486|\n|[1515.0,1515.0,0....|             1521.0|1481.2434072179851|      0.02613845679290919|\n+--------------------+-------------------+------------------+-------------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql.functions import col, abs\n\npredictions = lr_model.transform(test_data)\npredictions = predictions.withColumn(\"absolute_percentage_error\", abs((col(\"out_ArrDelayMinutes\") - col(\"prediction\")) / col(\"out_ArrDelayMinutes\")))\nmape = predictions.selectExpr(\"avg(absolute_percentage_error) as mape\").collect()[0][\"mape\"] * 100\n\nprint(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\npredictions.orderBy(desc(\"features\")).show()"}, {"cell_type": "code", "execution_count": 12, "id": "0bd840a0-6816-4552-bf16-9143961a152b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/06/22 16:28:20 WARN DAGScheduler: Broadcasting large task binary with size 1135.2 KiB\n24/06/22 16:28:23 WARN DAGScheduler: Broadcasting large task binary with size 1574.2 KiB\n24/06/22 16:28:27 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n24/06/22 16:28:31 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n24/06/22 16:28:36 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n24/06/22 16:28:41 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/06/22 16:28:46 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n24/06/22 16:28:51 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n24/06/22 16:28:57 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n24/06/22 16:29:02 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n24/06/22 16:29:07 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n24/06/22 16:29:12 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/06/22 16:29:16 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n24/06/22 16:29:21 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n24/06/22 16:29:25 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n24/06/22 16:29:29 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n24/06/22 16:29:33 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Training time (s): 151.82955145835876\n"}, {"name": "stderr", "output_type": "stream", "text": "24/06/22 16:29:38 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n[Stage 97:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+------------------+\n|            features|out_ArrDelayMinutes|        prediction|\n+--------------------+-------------------+------------------+\n|      (5,[0],[17.0])|               17.0|16.642857142857142|\n|      (5,[0],[18.0])|               17.0| 18.19047619047619|\n|      (5,[0],[33.0])|               18.0|22.897832817337463|\n|      (5,[0],[48.0])|               34.0| 31.50925925925926|\n|      (5,[0],[50.0])|               35.0| 31.50925925925926|\n|     (5,[0],[135.0])|              119.0|151.54088050314465|\n|(5,[0,1],[15.0,15...|               15.0|16.551666666666666|\n|(5,[0,1],[17.0,17...|               17.0|16.592814371257486|\n|(5,[0,1],[18.0,15...|               15.0|16.780262143407864|\n|(5,[0,1],[18.0,16...|               16.0|16.780262143407864|\n|(5,[0,1],[18.0,16...|               16.0|16.780262143407864|\n|(5,[0,1],[18.0,17...|               17.0|16.780262143407864|\n|(5,[0,1],[18.0,18...|               18.0|16.780262143407864|\n|(5,[0,1],[19.0,17...|               17.0| 17.10810810810811|\n|(5,[0,1],[19.0,19...|               19.0| 17.10810810810811|\n|(5,[0,1],[20.0,19...|               19.0|  17.4088200238379|\n|(5,[0,1],[20.0,20...|               20.0|  17.4088200238379|\n|(5,[0,1],[20.0,20...|               20.0|  17.4088200238379|\n|(5,[0,1],[21.0,16...|               16.0| 17.82601254991443|\n|(5,[0,1],[21.0,16...|               16.0| 17.82601254991443|\n|(5,[0,1],[21.0,16...|               16.0| 17.82601254991443|\n|(5,[0,1],[21.0,19...|               19.0| 17.82601254991443|\n|(5,[0,1],[22.0,15...|               15.0|18.309866666666668|\n|(5,[0,1],[22.0,15...|               15.0|18.309866666666668|\n|(5,[0,1],[22.0,15...|               15.0|18.309866666666668|\n|(5,[0,1],[22.0,17...|               17.0|18.309866666666668|\n|(5,[0,1],[23.0,17...|               17.0| 18.63906792265741|\n|(5,[0,1],[23.0,18...|               18.0| 18.63906792265741|\n|(5,[0,1],[23.0,18...|               18.0| 18.63906792265741|\n|(5,[0,1],[23.0,20...|               20.0| 18.63906792265741|\n|(5,[0,1],[23.0,20...|               20.0| 18.63906792265741|\n|(5,[0,1],[23.0,22...|               22.0| 18.63906792265741|\n|(5,[0,1],[24.0,15...|               15.0|18.593719806763286|\n|(5,[0,1],[24.0,16...|               16.0|18.593719806763286|\n|(5,[0,1],[24.0,17...|               17.0|18.593719806763286|\n|(5,[0,1],[24.0,17...|               17.0|18.593719806763286|\n|(5,[0,1],[24.0,20...|               20.0|18.593719806763286|\n|(5,[0,1],[24.0,21...|               21.0|18.593719806763286|\n|(5,[0,1],[24.0,23...|               23.0|18.593719806763286|\n|(5,[0,1],[25.0,16...|               16.0| 18.54218009478673|\n|(5,[0,1],[25.0,22...|               22.0| 18.54218009478673|\n|(5,[0,1],[26.0,15...|               15.0|18.685987903225808|\n|(5,[0,1],[26.0,17...|               17.0|18.685987903225808|\n|(5,[0,1],[26.0,19...|               19.0|18.685987903225808|\n|(5,[0,1],[27.0,16...|               16.0|19.119519270617488|\n|(5,[0,1],[27.0,17...|               17.0|19.119519270617488|\n|(5,[0,1],[27.0,21...|               21.0|19.119519270617488|\n|(5,[0,1],[27.0,24...|               24.0|24.962924281984336|\n|(5,[0,1],[27.0,25...|               25.0|24.962924281984336|\n|(5,[0,1],[27.0,26...|               26.0|24.962924281984336|\n+--------------------+-------------------+------------------+\nonly showing top 50 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Decision Tree\n\nfrom pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml.feature import Imputer\nimport time\n\ndt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"out_ArrDelayMinutes\",maxDepth=30)\n\nstart=time.time()\nmodel = dt.fit(train_data)\nend=time.time()\nduration=end-start\nprint(\"Training time (s):\",duration)\npredictions = model.transform(test_data)\npredictions.show(50)"}, {"cell_type": "code", "execution_count": 13, "id": "0d679d48-9b43-4c11-a87e-4be51d647bf0", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/06/22 16:30:27 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+------------------+\n|            features|out_ArrDelayMinutes|        prediction|\n+--------------------+-------------------+------------------+\n|[2554.0,2554.0,0....|             2565.0|214.19537934968625|\n|[2369.0,2365.0,0....|             2371.0|160.47692307692307|\n|[2112.0,2112.0,0....|             2135.0|  219.010101010101|\n|[1961.0,1877.0,0....|             1934.0|300.82123992215736|\n|[1915.0,20.0,0.0,...|             1890.0|152.83197947840958|\n|[1773.0,1773.0,0....|             1782.0|214.19537934968625|\n|[1757.0,22.0,1740...|             1762.0|233.89655172413794|\n|[1710.0,1710.0,0....|             1722.0|200.71485943775102|\n|[1707.0,224.0,0.0...|             1682.0|300.82123992215736|\n|[1676.0,1676.0,0....|             1678.0| 217.0924369747899|\n|[1670.0,1670.0,0....|             1747.0|  285.675816993464|\n|[1646.0,1646.0,0....|             1671.0|255.84848484848484|\n|[1634.0,1634.0,0....|             1646.0|200.71485943775102|\n|[1605.0,1605.0,0....|             1639.0|         247.28125|\n|[1559.0,0.0,0.0,1...|             1560.0|164.34895833333334|\n|[1557.0,1557.0,0....|             1597.0|  285.675816993464|\n|[1552.0,1552.0,0....|             1557.0|214.19537934968625|\n|[1551.0,1464.0,0....|             1559.0| 323.8208722741433|\n|[1519.0,0.0,0.0,3...|             1522.0|165.40804800564771|\n|[1515.0,1515.0,0....|             1521.0|214.19537934968625|\n+--------------------+-------------------+------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "24/06/22 16:30:46 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n[Stage 99:====================================================>   (68 + 4) / 72]\r"}, {"name": "stdout", "output_type": "stream", "text": "Mean Absolute Percentage Error (MAPE): 40.31%\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.orderBy(desc(\"features\")).show()\npredictions = predictions.withColumn(\"absolute_percentage_error\", abs((col(\"out_ArrDelayMinutes\") - col(\"prediction\")) / col(\"out_ArrDelayMinutes\")))\nmape = predictions.selectExpr(\"avg(absolute_percentage_error) as mape\").collect()[0][\"mape\"] * 100\n\nprint(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"}, {"cell_type": "code", "execution_count": 14, "id": "7955bb30-c981-4bce-9d43-a12341d6f122", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/06/22 16:32:13 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n24/06/22 16:32:42 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n24/06/22 16:32:44 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n24/06/22 16:33:03 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "r2: 0.6104848428322788\nrmse: 29.094148072500673\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(labelCol='out_ArrDelayMinutes', predictionCol='prediction')\nr2 = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\nrmse = evaluator.evaluate(predictions, {evaluator.metricName: 'rmse'})\nprint(\"r2:\",r2)\nprint(\"rmse:\",rmse)"}, {"cell_type": "code", "execution_count": null, "id": "4f1959b1-5110-4342-aa0e-3f04ab5fd8a2", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}